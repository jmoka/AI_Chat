import { enviarMensagem } from '../controllers/enviarMensagem.js';
import { listaHistorico } from '../controllers/historicoMSG.js';
import salvarConversa from '../controllers/salvarMensagens.js';
import EscolherModelo from '../controllers/escolherModelo.js'; // Importa a fun√ß√£o EscolherModelo

export function rotaChat(app) {
  app.post('/api/chat', async (req, res) => { // Rota para enviar mensagens para o modelo LLM
    try {
      const { // Mensagem do usu√°rio
        mensagem,
        orientacao,
        arquivos = [],
        // historico, // precisa ser um array de mensagens [{ role, content }, ...]
        modelo,
      } = req.body; // Extraindo dados do corpo da requisi√ß√£o e definindo valores padr√£o

      const historicoMemoria = listaHistorico(); // Carrega o hist√≥rico de mensagens do arquivo de log
      const historicoFinal = Array.isArray(historicoMemoria) ? historicoMemoria : listaHistorico(); // Se o hist√≥rico n√£o for um array, usa o hist√≥rico carregado do log

        // Ordena pela propriedade timestamp, se existir
      historicoFinal.sort((a, b) => {
        if (a.timestamp && b.timestamp) {
          return new Date(b.timestamp) - new Date(a.timestamp); // Mais recente primeiro
        }
        return 0; // Mant√©m a ordem original caso n√£o tenha timestamp
      });

      // Verifica se a mensagem n√£o est√° vazia ou nula
      // Se estiver vazia, retorna erro 400 (Bad Request)
      if (!mensagem || mensagem.trim() === "") {
        return res.status(400).json({ error: "Campo obrigat√≥rio: mensagem n√£o pode estar vazia." });
      }
      

      //
      const mensagens = [ // Cria um array de mensagens para enviar ao modelo LLM
        { role: "system", content: orientacao },
        ...historicoFinal,
        { role: "user", content: mensagem }
      ];

      console.log("üß™ Mensagens finais:", mensagens);

      const modeloEscolhido = EscolherModelo(modelo)

      const resposta = await enviarMensagem(
        mensagens,
        // orientacao,
        // arquivos,
        // historicoFinal,
        modelo
      );

      const respostaDaIA = resposta.choices[0]?.message?.content || "";

      const mensagemSalvaJSON = [
        { role: "user", content: mensagem },
        { role: "assistant", content: respostaDaIA }
      ];

      // console.log("üì¶ Nova intera√ß√£o:", mensagemSalvaJSON);
      salvarConversa(mensagemSalvaJSON);
      
      
      return res.json({
        resposta: respostaDaIA,
        modeloUsado: modeloEscolhido,
      });

    } catch (erro) {
      console.error("‚ùå Erro na rota /api/chat:", erro);
      return res.status(500).json({ error: "Erro ao gerar resposta com modelo LLM." });
    }
  });
}
