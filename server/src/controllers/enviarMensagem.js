// Importa o SDK oficial da Groq para interagir com os modelos de linguagem da plataforma Groq
import Groq from "groq-sdk";

// Carrega as vari√°veis de ambiente do arquivo .env
import dotenv from 'dotenv';
dotenv.config(); // ‚Üê ESSENCIAL para ativar o uso de process.env

import EscolherModelo from "./escolherModelo.js";           // Retorna o modelo a ser usado
// import { listaHistorico } from "./historicoMSG.js";     // Retorna o hist√≥rico de mensagens

// Cria uma inst√¢ncia da API Groq usando a chave armazenada no .env
const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });


// Fun√ß√£o principal que envia mensagem ao modelo Groq
export async function enviarMensagem(mensagens, modelo, temperatura, presence_penalty, frequency_penalty, token, top_p  ) {

    /*
    presence_penalty Penaliza a repeti√ß√£o de t√≥picos j√° abordados. Intervalo: -2.0 a 2.0
    Valores positivos incentivam novidades (trazer coisas novas).
    Valores negativos permitem mais repeti√ß√£o de t√≥picos.
    Ex: presence_penalty: 1 ‚Üí estimula o modelo a explorar novos assuntos.
    */
    const presence_penaltyEnviado = presence_penalty || 1

        /*
        frequency_penalty Penaliza a repeti√ß√£o de palavras e frases j√° usadas.
        Intervalo: -2.0 a 2.0
        Controla a varia√ß√£o no vocabul√°rio.
        frequency_penalty: 1 ‚Üí reduz repeti√ß√µes de palavras.        
        */

    const frequency_penaltyEnviado = frequency_penalty || 1


    // Define o limite m√°ximo de tokens na resposta. ate 6000
    const TokenEnviado = token || 3000

    /*
    top_p (tamb√©m chamado de nucleus sampling) Controla a diversidade da resposta.
    Intervalo: 0.0 a 1.0
    Em vez de considerar todas as palavras poss√≠veis, seleciona entre as mais prov√°veis que somem at√© top_p de probabilidade.
    top_p: 1.0 = considera todas as op√ß√µes poss√≠veis (sem corte).
    top_p: 0.8 = considera apenas as palavras mais prov√°veis.
    */
    const top_pEnviado = top_p || 1   


   
    mensagens.forEach((msg, index) => { // Verifica cada mensagem
      //  console.log(`üîç Validando mensagem ${index}:`, msg);
        if (!msg.role || !msg.content || msg.content.trim() === "") { // Verifica se a mensagem tem role e content
            throw new Error(`‚ùå A mensagem no √≠ndice ${index} est√° incompleta (role/content ausente ou vazio).`);
        }
    });

    const resposta = await groq.chat.completions.create({ // Envia a mensagem para o modelo Groq
        messages: mensagens,        
        model: modelo,
        temperature: Number(temperatura), // Baixa temperatura (0.1 a 0.5): Respostas mais focadas e determin√≠sticas. Alta temperatura (0.5 a 1.0): Respostas mais criativas e imprevis√≠veis.
        presence_penalty: presence_penaltyEnviado,
        frequency_penalty: frequency_penaltyEnviado,
        max_tokens: TokenEnviado,
        top_p: top_pEnviado,
        
        
    });

    return resposta; // Retorna a resposta da IA
}

